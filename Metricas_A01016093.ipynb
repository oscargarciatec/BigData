{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19032e6b",
   "metadata": {},
   "source": [
    "# üéì **Maestr√≠a en Inteligencia Artificial Aplicada**\n",
    "\n",
    "## üìà **Curso: An√°lisis de grandes vol√∫menes de datos (Gpo 10)**\n",
    "\n",
    "### üèõÔ∏è Tecnol√≥gico de Monterrey\n",
    "\n",
    "#### üë®‚Äçüè´ **Profesor titular:** Dr. Iv√°n Olmos Pineda\n",
    "#### üë©‚Äçüè´ **Profesor asistence:** Ver√≥nica Sandra Guzm√°n de Valle\n",
    "\n",
    "### üìä **Actividad 4 | M√©tricas de calidad de resultados**\n",
    "\n",
    "#### üìÖ **6 de junio de 2025**\n",
    "\n",
    "üßë‚Äçüíª **A01016093:** Oscar Enrique Garc√≠a Garc√≠a "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901a707",
   "metadata": {},
   "source": [
    "# 1. Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f91db383",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m col, rand\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, rand\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3caec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Actividad4_MetricasCalidad\").getOrCreate()\n",
    "df = spark.read.parquet(\"/ruta/a/tu/dataset/parquet\")\n",
    "\n",
    "condiciones_climaticas = [\"Fair\", \"Mostly Cloudy\", \"Cloudy\", \"Partly Cloudy\", \"Clear\", \"Light Rain\", \"Overcast\"]\n",
    "severidades = [2, 3]\n",
    "\n",
    "particiones = []\n",
    "for clima in condiciones_climaticas:\n",
    "    for severidad in severidades:\n",
    "        particion = df.filter((col(\"Weather_Condition\") == clima) & (col(\"Severity\") == severidad)).limit(1000)\n",
    "        particiones.append(particion)\n",
    "\n",
    "muestra_M = particiones[0]\n",
    "for part in particiones[1:]:\n",
    "    muestra_M = muestra_M.union(part)\n",
    "\n",
    "muestra_M.cache()\n",
    "muestra_M.write.mode(\"overwrite\").parquet(\"/ruta/salida/muestra_M\")\n",
    "\n",
    "muestra_pd = muestra_M.select(\"Severity\", \"Weather_Condition\").toPandas()\n",
    "plt.figure(figsize=(10, 5))\n",
    "muestra_pd.groupby([\"Weather_Condition\", \"Severity\"]).size().unstack().plot(kind='bar', stacked=True)\n",
    "plt.title(\"Distribuci√≥n de la muestra por condici√≥n clim√°tica y severidad\")\n",
    "plt.ylabel(\"N√∫mero de registros\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "train_test_particiones = []\n",
    "for part in particiones:\n",
    "    train, test = part.randomSplit([0.7, 0.3], seed=42)\n",
    "    train_test_particiones.append((train, test))\n",
    "\n",
    "train_df = train_test_particiones[0][0]\n",
    "test_df = train_test_particiones[0][1]\n",
    "for t, s in train_test_particiones[1:]:\n",
    "    train_df = train_df.union(t)\n",
    "    test_df = test_df.union(s)\n",
    "\n",
    "features_cols = [\"Temperature\", \"Humidity\", \"Visibility\", \"Wind_Speed\", \"Precipitation\"]\n",
    "assembler = VectorAssembler(inputCols=features_cols, outputCol=\"raw_features\")\n",
    "scaler = StandardScaler(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "label_indexer = StringIndexer(inputCol=\"Severity\", outputCol=\"label\")\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=20, maxDepth=6)\n",
    "pipeline = Pipeline(stages=[assembler, scaler, label_indexer, rf])\n",
    "model = pipeline.fit(train_df)\n",
    "predictions = model.transform(test_df)\n",
    "\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "metricas_df = pd.DataFrame({\n",
    "    'M√©trica': ['Accuracy', 'Precision', 'Recall'],\n",
    "    'Valor': [accuracy, precision, recall]\n",
    "})\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(metricas_df['M√©trica'], metricas_df['Valor'], color='skyblue')\n",
    "plt.title('M√©tricas de Evaluaci√≥n del Modelo')\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Puntaje')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
